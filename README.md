# SER-with-ConvNet-and-MFCCs
"Speech Emotion Recognition with ConvNet and MFCCs" employs Convolutional Neural Networks (ConvNet) to extract patterns from Mel-frequency cepstral coefficients (MFCCs) in speech data. This method aims to discern and classify emotions conveyed through spoken words or expressions.

# Dataset
To use this code, download the dataset from the following link:


[Toronto emotional speech set (TESS) dataset](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)


[RAVDESS Emotional speech audio (RAVDESS) dataset](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
